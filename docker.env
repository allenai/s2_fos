### Model Config
ARTIFACTS_DIR=/opt/ml/artifacts

### Inference Server Config
BATCH_SIZE=1
MODEL_SERVER_TIMEOUT=60
NUM_WORKERS=1
